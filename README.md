## Общая структура

Есть три сущности: 
- Fetcher, который забирает данные из источника и складывает в базу. Имеет параметр url и file. 
Первый - для изменения пути запроса, второй - для mock-чтения из файла (для отладки).
- Server, который обрабатывает соединения от клиентов во веб-сокетам.
- Демо-клиент, который умеет подписываться на сообщения от сервера

## Примечания
1) Использовал mysql исключительно в демонстрационных целях, потому что легко и быстро поднять.
Понятно, что для этой задачи в прод такое использовать нельзя и лучше использовать что-то из числа
time series БД.

В идеале задача звучит как что-то, для чего нужно использовать кольцевой буфер. В mysql/psql я такого не нашел.
Можно было бы попробовать использовать для монги https://www.mongodb.com/docs/manual/core/capped-collections/

Но скорее всего, на самом деле возникла бы потребность хранить данные за более долгий срок (для отладки и разбора
инцедентов, например), поэтому можно было просто каждый день хранить в новой таблице. Тогда у нас было бы
5 валют/сек * 60 сек * 60 мин * 24 = 432к записей в сутки при условии, что мы все валюты пишем в одну таблицу.
0.5М записей в таблице не проблема даже для mysql.

Важная оговорка про вермя: в реализации нет дополнительного контроля, что мы отправляем данные **ровно** раз в секунду. 
Раз в секунду сервер выбирает последнюю во времени запись из базы по интересующему типу ассета. Исхожу из допущения, 
что повторно отправить тот же датапоинт в случае отставания не критично. 

2) Нет буфера для записи. В большой архитектуре можно было бы сделать API-воркеры, которые забирают данные из источников,
генерируют какие-то события в какую-то очердь, и другие воркеры-потребители разбирают из этих очередей сообщения, складывая
в БД. Было бы актуально для большого количества источников данных. 
А тут мы пишем в БД каждую секунду по пять записей за раз. Запись раз в секунду - это вряд ли страшно, 
но потенциально это очевидный ботлнек.

3) Функция cleanup_response использует срезы, а не removesuffix/removeprefix, чтобы работало на py3.9 и ниже.

4) Для простоты в валидации не используются библиотеки типа Marshmallow/Pydantic.

5) Задача выглядит похоже на проверку скиллов system design (среди прочего), а сисдиз обычно подразумевает 
интерактивный диалог со сбором ТЗ  и уточнением деталей и корнер-кейсов. 
Но раз это формат "домашки", видимо, активное уточнение не подразумевается, поэтому
при выполнении исхожу из того, что если что-то не указано, то этого делать не стоит.
Например, в описании механизма пере-подписки на новую валюту не сказано, что история должна высылаться для новой
валюты тоже, поэтому это реализовывать не стал. 

6) Тесты покрывают не все кейсы и не декомпозированы: позитивный кейс 
"подписка-получение истории - получение датапоинта - подписка на следующий ассет - получение нового датапоинта" 
выполнено в одном тесте. Это, разумеется, не для production.

7) Аналогично с подключением и сокетами. Подключение создается каждый раз заново - в идеале его нужно переиспользовать, 
создавать пул подключений, и тд. 
Gracefull обработки клиента, который отключился, тоже нет. Проверка ssl отключена. 

8) Полный make с настройкой окружения не делал также в рамках экономии времени. Есть запуск тестов и миграции

 ## Команды:
- ```make migrate``` запустит миграцию для запущенного в докере контейнера mysql (имя контейнера захардкожено)
- ```make tests``` запустит тесты
- ```make run``` запустит docker compose с контейнером mysql. Нужен установленный docker compose. 

### Запуск fetcher. 
Если указать путь к файлу через параметр -f, будет использован конент из этого файла. Ожидается,
что в файле лежит контент такого же формата, как отдается по исходному URL.

``` python /path/to/project/ibit_test/fetcher/fetcher.py -f /path/to/project/ibit_test/resource/data_displayer_raw.json```  

Если запустить без флагов, то будет использован url по умолчанию:
``` python /path/to/project/ibit_test/fetcher/fetcher.py```
Проверка ssl при этом выполняться не будет.

### Запуск websocket-сервера
``` python /path/to/project/ibit_test/server/app.py```

Запускается всегда на порту 8080. Конфигурирование сервера не реализовывал.

### Запуск демо-клиента
``` python /path/to/project/ibit_test/server/client.py```

9) По умолчанию как источник данных используется файл resource/data_displayer_raw.json (хоть там и не совсем json из-за префикса "null(").
Это сохраненная выдача описанного в ТЗ эндпоинта https://ratesjson.fxcm.com/DataDisplayer. Зависимость aiofiles 
используется для чтения контента файла с диска. 